CSCI159 - Natural Language Processing
Pine, Anjali
09/17/24

What is the best lambda smoothing parameter?
Development File
model 1 (0.1) : 63.73132288637212
model 2 (0.01): 43.68236600240003
model 3 (0.001): 36.08948111375689
model 4 (0.0001): 34.75148986130219
model 5 (0.00001): 34.613175504824774
model 6 (0.000001): 34.662586348571196
model 7 (0.0000001): 34.48520100538355
model 8 (0.00000001): 34.4363288307949
Test File
model 1 (0.1): 64.3166538296586
model 2 (0.01): 43.48238406837255
model 3 (0.001): 36.70219198874578
model 4 (0.0001): 35.13958379155097
model 5 (0.00001): 35.15101589081593
model 6 (0.000001): 34.604189112749395
model 7 (0.0000001): 35.16693870093668
model 8 (0.00000001): 35.118262408845936
It seems that the best lambda is the lowest one, i.e. 0.00000001. The lower the lambda number is, the lower our perplexity is as well. 

What is the best discount? 
Development File (0.99, 0.9, 0.75, 0.5, 0.25, 0.1)
model 1 (0.99): 53.32040947187919
model 2 (0.9): 44.93477838459815
model 3 (0.75): 41.184766374725314
model 4 (0.5): 37.6475313961236
model 5 (0.25): 35.83315601686389
model 6 (0.1): 35.6433550049303
Test File (0.99, 0.9, 0.75, 0.5, 0.25, 0.1)
model 1 (0.99): 53.58513785417338
model 2 (0.9): 44.869933497250535
model 3 (0.75): 41.319168816493814
model 4 (0.5): 38.05546886017002
model 5 (0.25): 36.03787485281308
model 6 (0.1): 35.66690069615999
The best discount on the dev and test set was 0.1, which was the smallest discount value. 

Performance
Which model is better? Provide some quantitative and/or qualitative arguments (including data or examples) of which approach is better. Make sure to clearly explain your evaluation approach and your arguments.
The discount model performed significantly better, as evidenced by the lower average perplexities compared to the lambda model. This is because the discount model more effectively reallocates probability mass, especially to rare and unseen events, by reducing the probability of frequent n-grams and redistributing it to less frequent ones. In contrast, the lambda model tends to assign too much probability mass to unseen events without considering their context or frequency, which leads to suboptimal performance.
Wrap-up
Very briefly answer the following questions: how long did you spend on this assignment?
What was the most fun part? least fun part? how would you improve it if I had to give it again?
15 hours. The most fun part was learning how to code in Java again. The least fun part was trying to get our perplexities to be the right value because our code logically makes sense and debugging it on smaller test cases worked. I think in the future, more explicit directions would be helpful as well as more mentor hours to help. 

Ethics
Of the six scenarios, which do you see as the most problematic? Give a couple of sentences justifying your answer.
I think the “Tyranny of AI Design” is the most problematic scenario. Since AIs are trained by biased data, the more we use AI, the more bias we feed into training. This potentially will create even larger disparities in an already segregated society, denying marginalized people of job opportunities, mortgage loans, health care, among others.

6. What is one scenario that is also concerning that is not listed here? It can be NLP-specific
or more broadly to AI
Related to the Deepfake example, AI could also impersonate a person’s voice and writing style if trained enough. This could lead to scams and fraud, where, for example, scammers can use your voice to ask for ransom from someone you know, or giving written consent to something you yourself did not agree to. 



